{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# OpenVaccine: COVID-19 mRNA Vaccine Degradation Prediction\n",
    "\n",
    "In this [Kaggle competition](https://www.kaggle.com/c/stanford-covid-vaccine/overview) we try to develop models and design rules for RNA degradation. As the overview of the competition states:\n",
    "\n",
    ">mRNA vaccines have taken the lead as the fastest vaccine candidates for COVID-19, but currently, they face key potential limitations. One of the biggest challenges right now is how to design super stable messenger RNA molecules (mRNA). Conventional vaccines (like your seasonal flu shots) are packaged in disposable syringes and shipped under refrigeration around the world, but that is not currently possible for mRNA vaccines.\n",
    ">\n",
    ">Researchers have observed that RNA molecules have the tendency to spontaneously degrade. This is a serious limitation--a single cut can render the mRNA vaccine useless. Currently, little is known on the details of where in the backbone of a given RNA is most prone to being affected. Without this knowledge, current mRNA vaccines against COVID-19 must be prepared and shipped under intense refrigeration, and are unlikely to reach more than a tiny fraction of human beings on the planet unless they can be stabilized.\n",
    "\n",
    "<img src=\"images/banner.png\" width=\"1000\" style=\"margin-left: auto; margin-right: auto;\"> \n",
    "\n",
    "The model should predict likely degradation rates at each base of an RNA molecule. The training data set is comprised of over 3000 RNA molecules and their degradation rates at each position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Install necessary packages\n",
    "\n",
    "We can install the necessary package by either running `pip install --user <package_name>` or include everything in a `requirements.txt` file and run `pip install --user -r requirements.txt`. Since we only need one extra package here we can use the former command.\n",
    "\n",
    "> NOTE: Do not forget to use the `--user` argument. It is necessary if you want to use Kale to transform this notebook into a Kubeflow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --user pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports\n",
    "\n",
    "In this section we import the packages we need for this example. Make it a habbit to gather your imports in a single place. It will make your life easier if you are going to transform this notebook into a Kubeflow pipeline using Kale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Project hyper-parameters\n",
    "\n",
    "In this cell, we define the different hyper-parameters. Defining them in one place makes it easier to experiment with their values and also facilitates the execution of HP tuning experiments using Kale and Katib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "LR = 1e-3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "EMBED_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "DROPOUT = .5\n",
    "SP_DROPOUT = .3\n",
    "TRAIN_SEQUENCE_LENGTH = 107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Set random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load and preprocess data\n",
    "\n",
    "In this section, we load and process the data set to get in a ready-to-use form by the model. First, let us load and analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The data are in `json` format, thus, we use the handy `read_json` pandas method. There is one train data set and two test sets (one public and one private)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"data/train.json\", lines=True)\n",
    "test_df = pd.read_json(\"data/test.json\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We also load the `sample_submission.csv` file, which will prove handy when we will be creating our submission to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let us now explore the data, their dimensions and what each column mean. To this end, we use the pandas `head` method to visualize a small sample (five rows by default) of our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>structure</th>\n",
       "      <th>predicted_loop_type</th>\n",
       "      <th>signal_to_noise</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>seq_scored</th>\n",
       "      <th>reactivity_error</th>\n",
       "      <th>deg_error_Mg_pH10</th>\n",
       "      <th>deg_error_pH10</th>\n",
       "      <th>deg_error_Mg_50C</th>\n",
       "      <th>deg_error_50C</th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_50C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>id_001f94081</td>\n",
       "      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n",
       "      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n",
       "      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n",
       "      <td>6.894</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n",
       "      <td>[0.26130000000000003, 0.38420000000000004, 0.1...</td>\n",
       "      <td>[0.2631, 0.28600000000000003, 0.0964, 0.1574, ...</td>\n",
       "      <td>[0.1501, 0.275, 0.0947, 0.18660000000000002, 0...</td>\n",
       "      <td>[0.2167, 0.34750000000000003, 0.188, 0.2124, 0...</td>\n",
       "      <td>[0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...</td>\n",
       "      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n",
       "      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n",
       "      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n",
       "      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>id_0049f53ba</td>\n",
       "      <td>GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...</td>\n",
       "      <td>.....(((((((((((((((((((((((....)))))))))).)))...</td>\n",
       "      <td>EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...</td>\n",
       "      <td>[73705.3985, 73705.3985, 73705.3985, 73705.398...</td>\n",
       "      <td>[10.1986, 9.2418, 5.0933, 5.0933, 5.0933, 5.09...</td>\n",
       "      <td>[16.6174, 13.868, 8.1968, 8.1968, 8.1968, 8.19...</td>\n",
       "      <td>[15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>id_006f36f57</td>\n",
       "      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n",
       "      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n",
       "      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n",
       "      <td>8.800</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n",
       "      <td>[0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...</td>\n",
       "      <td>[0.17020000000000002, 0.178, 0.111, 0.091, 0.0...</td>\n",
       "      <td>[0.1033, 0.1464, 0.1126, 0.09620000000000001, ...</td>\n",
       "      <td>[0.14980000000000002, 0.1761, 0.1517, 0.116700...</td>\n",
       "      <td>[0.44820000000000004, 1.4822, 1.1819, 0.743400...</td>\n",
       "      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n",
       "      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n",
       "      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n",
       "      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>id_0082d463b</td>\n",
       "      <td>GGAAAAGCGCGCGCGCGCGCGCGAAAAAGCGCGCGCGCGCGCGCGC...</td>\n",
       "      <td>......((((((((((((((((......))))))))))))))))((...</td>\n",
       "      <td>EEEEEESSSSSSSSSSSSSSSSHHHHHHSSSSSSSSSSSSSSSSSS...</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[3.5229, 6.0748, 3.0374, 3.0374, 3.0374, 3.037...</td>\n",
       "      <td>[73705.3985, 73705.3985, 73705.3985, 73705.398...</td>\n",
       "      <td>[11.8007, 12.7566, 5.7733, 5.7733, 5.7733, 5.7...</td>\n",
       "      <td>[121286.7181, 121286.7182, 121286.7181, 121286...</td>\n",
       "      <td>[15.3995, 8.1124, 7.7824, 7.7824, 7.7824, 7.78...</td>\n",
       "      <td>[0.0, 2.2399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.0, -0.5083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[3.4248, 6.8128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.0, -0.8365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>id_0087940f4</td>\n",
       "      <td>GGAAAAUAUAUAAUAUAUUAUAUAAAUAUAUUAUAGAAGUAUAAUA...</td>\n",
       "      <td>.....(((((((.((((((((((((.(((((((((....)))))))...</td>\n",
       "      <td>EEEEESSSSSSSBSSSSSSSSSSSSBSSSSSSSSSHHHHSSSSSSS...</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>68</td>\n",
       "      <td>[1.665, 2.1728, 2.0041, 1.2405, 0.620200000000...</td>\n",
       "      <td>[4.2139, 3.9637000000000002, 3.2467, 2.4716, 1...</td>\n",
       "      <td>[3.0942, 3.015, 2.1212, 2.0552, 0.881500000000...</td>\n",
       "      <td>[2.6717, 2.4818, 1.9919, 2.5484999999999998, 1...</td>\n",
       "      <td>[1.3285, 3.6173, 1.3057, 1.3021, 1.1507, 1.150...</td>\n",
       "      <td>[0.8267, 2.6577, 2.8481, 0.40090000000000003, ...</td>\n",
       "      <td>[2.1058, 3.138, 2.5437000000000003, 1.0932, 0....</td>\n",
       "      <td>[4.7366, 4.6243, 1.2068, 1.1538, 0.0, 0.0, 0.7...</td>\n",
       "      <td>[2.2052, 1.7947000000000002, 0.7457, 3.1233, 0...</td>\n",
       "      <td>[0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index            id                                           sequence  \\\n",
       "0      0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n",
       "1      1  id_0049f53ba  GGAAAAAGCGCGCGCGGUUAGCGCGCGCUUUUGCGCGCGCUGUACC...   \n",
       "2      2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n",
       "3      3  id_0082d463b  GGAAAAGCGCGCGCGCGCGCGCGAAAAAGCGCGCGCGCGCGCGCGC...   \n",
       "4      4  id_0087940f4  GGAAAAUAUAUAAUAUAUUAUAUAAAUAUAUUAUAGAAGUAUAAUA...   \n",
       "\n",
       "                                           structure  \\\n",
       "0  .....((((((.......)))).)).((.....((..((((((......   \n",
       "1  .....(((((((((((((((((((((((....)))))))))).)))...   \n",
       "2  .....((((.((.....((((.(((.....)))..((((......)...   \n",
       "3  ......((((((((((((((((......))))))))))))))))((...   \n",
       "4  .....(((((((.((((((((((((.(((((((((....)))))))...   \n",
       "\n",
       "                                 predicted_loop_type  signal_to_noise  \\\n",
       "0  EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n",
       "1  EEEEESSSSSSSSSSSSSSSSSSSSSSSHHHHSSSSSSSSSSBSSS...            0.193   \n",
       "2  EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n",
       "3  EEEEEESSSSSSSSSSSSSSSSHHHHHHSSSSSSSSSSSSSSSSSS...            0.104   \n",
       "4  EEEEESSSSSSSBSSSSSSSSSSSSBSSSSSSSSSHHHHSSSSSSS...            0.423   \n",
       "\n",
       "   SN_filter  seq_length  seq_scored  \\\n",
       "0          1         107          68   \n",
       "1          0         107          68   \n",
       "2          1         107          68   \n",
       "3          0         107          68   \n",
       "4          0         107          68   \n",
       "\n",
       "                                    reactivity_error  \\\n",
       "0  [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...   \n",
       "1  [2.8272, 2.8272, 2.8272, 4.7343, 2.5676, 2.567...   \n",
       "2  [0.0931, 0.13290000000000002, 0.11280000000000...   \n",
       "3  [3.5229, 6.0748, 3.0374, 3.0374, 3.0374, 3.037...   \n",
       "4  [1.665, 2.1728, 2.0041, 1.2405, 0.620200000000...   \n",
       "\n",
       "                                   deg_error_Mg_pH10  \\\n",
       "0  [0.26130000000000003, 0.38420000000000004, 0.1...   \n",
       "1  [73705.3985, 73705.3985, 73705.3985, 73705.398...   \n",
       "2  [0.1365, 0.2237, 0.1812, 0.1333, 0.1148, 0.160...   \n",
       "3  [73705.3985, 73705.3985, 73705.3985, 73705.398...   \n",
       "4  [4.2139, 3.9637000000000002, 3.2467, 2.4716, 1...   \n",
       "\n",
       "                                      deg_error_pH10  \\\n",
       "0  [0.2631, 0.28600000000000003, 0.0964, 0.1574, ...   \n",
       "1  [10.1986, 9.2418, 5.0933, 5.0933, 5.0933, 5.09...   \n",
       "2  [0.17020000000000002, 0.178, 0.111, 0.091, 0.0...   \n",
       "3  [11.8007, 12.7566, 5.7733, 5.7733, 5.7733, 5.7...   \n",
       "4  [3.0942, 3.015, 2.1212, 2.0552, 0.881500000000...   \n",
       "\n",
       "                                    deg_error_Mg_50C  \\\n",
       "0  [0.1501, 0.275, 0.0947, 0.18660000000000002, 0...   \n",
       "1  [16.6174, 13.868, 8.1968, 8.1968, 8.1968, 8.19...   \n",
       "2  [0.1033, 0.1464, 0.1126, 0.09620000000000001, ...   \n",
       "3  [121286.7181, 121286.7182, 121286.7181, 121286...   \n",
       "4  [2.6717, 2.4818, 1.9919, 2.5484999999999998, 1...   \n",
       "\n",
       "                                       deg_error_50C  \\\n",
       "0  [0.2167, 0.34750000000000003, 0.188, 0.2124, 0...   \n",
       "1  [15.4857, 7.9596, 13.3957, 5.8777, 5.8777, 5.8...   \n",
       "2  [0.14980000000000002, 0.1761, 0.1517, 0.116700...   \n",
       "3  [15.3995, 8.1124, 7.7824, 7.7824, 7.7824, 7.78...   \n",
       "4  [1.3285, 3.6173, 1.3057, 1.3021, 1.1507, 1.150...   \n",
       "\n",
       "                                          reactivity  \\\n",
       "0  [0.3297, 1.5693000000000001, 1.1227, 0.8686, 0...   \n",
       "1  [0.0, 0.0, 0.0, 2.2965, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "2  [0.44820000000000004, 1.4822, 1.1819, 0.743400...   \n",
       "3  [0.0, 2.2399, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0....   \n",
       "4  [0.8267, 2.6577, 2.8481, 0.40090000000000003, ...   \n",
       "\n",
       "                                         deg_Mg_pH10  \\\n",
       "0  [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n",
       "3  [0.0, -0.5083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "4  [2.1058, 3.138, 2.5437000000000003, 1.0932, 0....   \n",
       "\n",
       "                                            deg_pH10  \\\n",
       "0  [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n",
       "1  [4.947, 4.4523, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n",
       "3  [3.4248, 6.8128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "4  [4.7366, 4.6243, 1.2068, 1.1538, 0.0, 0.0, 0.7...   \n",
       "\n",
       "                                          deg_Mg_50C  \\\n",
       "0  [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n",
       "1  [4.8511, 4.0426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n",
       "3  [0.0, -0.8365, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0...   \n",
       "4  [2.2052, 1.7947000000000002, 0.7457, 3.1233, 0...   \n",
       "\n",
       "                                             deg_50C  \n",
       "0  [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...  \n",
       "1  [7.6692, 0.0, 10.9561, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "2  [0.9501000000000001, 1.7974999999999999, 1.499...  \n",
       "3  [7.6692, -1.3223, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  \n",
       "4  [0.0, 5.1198, -0.3551, -0.3518, 0.0, 0.0, 0.0,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We see a lot of strange entries, so, let us try to see what they are:\n",
    "\n",
    "* `sequence`: An 107 characters long string in Train and Public Test (130 in Private Test), which describes the RNA sequence, a combination of A, G, U, and C for each sample.\n",
    "* `structure`: An 107 characters long string in Train and Public Test (130 in Private Test), which is a compination of `(`, `)`, and `.` characters that describe whether a base is estimated to be paired or unpaired. Paired bases are denoted by opening and closing parentheses (e.g. (....) means that base 0 is paired to base 5, and bases 1-4 are unpaired).\n",
    "* `predicted_loop_type`: An 107 characters long string, which describes the structural context (also referred to as 'loop type') of each character in sequence. Loop types assigned by bpRNA from Vienna RNAfold 2 structure. From the bpRNA_documentation: `S`: paired \"Stem\" `M`: Multiloop `I`: Internal loop `B`: Bulge `H`: Hairpin loop `E`: dangling End `X`: eXternal loop.\n",
    "\n",
    "Then, we have `signal_to_noise`, which is quality control feature. It records the measurements relative to their errors; the higher value the more confident measurements are.\n",
    "\n",
    "The `*_error_*` columns calculate the errors in experimental values obtained in corresponding `reactivity` and `deg_*` columns.\n",
    "\n",
    "The last five columns (i.e., `recreativity` and `deg_*`) are out depended variables, our targets. Thus, for every base in the molecule we should predict five different values.\n",
    "\n",
    "The `bpps` folder stands for Base Pairing Probabilities. In contains numpy arrays that correspond to the Base Pairing Probability Matrix (BPPM). The `bpps` are pre-calculated for each sequence. They are matrices of base pair probabilities. Biophysically speaking, this matrix gives the probability that each pair of nucleotides, in the RNA, forms a base pair (given a particular model of RNA folding). Thus, let us provide some helper functions to load these arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bpps_sum(df):\n",
    "    bpps_arr = []\n",
    "    for mol_id in df.id.to_list():\n",
    "        bpps_arr.append(np.load(f\"data/bpps/{mol_id}.npy\").max(axis=1))\n",
    "    return bpps_arr\n",
    "\n",
    "\n",
    "def read_bpps_max(df):\n",
    "    bpps_arr = []\n",
    "    for mol_id in df.id.to_list():\n",
    "        bpps_arr.append(np.load(f\"data/bpps/{mol_id}.npy\").sum(axis=1))\n",
    "    return bpps_arr\n",
    "\n",
    "\n",
    "def read_bpps_nb(df):\n",
    "    # normalized non-zero number\n",
    "    # from https://www.kaggle.com/symyksr/openvaccine-deepergcn \n",
    "    bpps_nb_mean = 0.077522 # mean of bpps_nb across all training data\n",
    "    bpps_nb_std = 0.08914   # std of bpps_nb across all training data\n",
    "    bpps_arr = []\n",
    "    for mol_id in df.id.to_list():\n",
    "        bpps = np.load(f\"data/bpps/{mol_id}.npy\")\n",
    "        bpps_nb = (bpps > 0).sum(axis=0) / bpps.shape[0]\n",
    "        bpps_nb = (bpps_nb - bpps_nb_mean) / bpps_nb_std\n",
    "        bpps_arr.append(bpps_nb)\n",
    "    return bpps_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "These are the main columns we care about. For more details, visit the competition [info](https://www.kaggle.com/c/stanford-covid-vaccine/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are now ready to preprocess the data set. First, we define the symbols that encode certain features (e.g. the base symbol or the structure), the features and the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "symbols = \"().ACGUBEHIMSX\"\n",
    "feat_cols = ['sequence', 'structure', 'predicted_loop_type']\n",
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']\n",
    "error_cols = ['reactivity_error', 'deg_error_Mg_pH10', 'deg_error_Mg_50C', 'deg_error_pH10', 'deg_error_50C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to encode values like strings or characters and feed them to the neural network, we need to tokenize them. The `Tokenizer` class will assign a number to each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=True, filters=\"\")\n",
    "tokenizer.fit_on_texts(symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Moreover, the tokenizer keeps a dictionary, `word_index`, from which we can get the number of elements in our vocabulary. In this case, we only have a few elements, but if we has passed a whole book, that function would be handy.\n",
    "\n",
    "> NOTE: We should add `1` to the length of the `word_index` dictionary to get the correct number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of elements in the vocabulary\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are now ready to process our features. First, we transform each character sequence (i.e., `sequence`, `structure`, `predicted_loop_type`) into number sequences and concatenate them together. Then, we add the previously extracted `bpps_*` features on top. The resulting shape should be `(num_examples, 107, 6)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # get the features\n",
    "    sequence_sentences = np.array(df[\"sequence\"].values.tolist())\n",
    "    structure_sentences = np.array(df[\"structure\"].values.tolist())\n",
    "    loop_sentences = np.array(df[\"predicted_loop_type\"].values.tolist())\n",
    "    \n",
    "    # transform character sequences into number sequences\n",
    "    sequence_tokens = tokenizer.texts_to_sequences(sequence_sentences)\n",
    "    structure_tokens = tokenizer.texts_to_sequences(structure_sentences)\n",
    "    loop_tokens = tokenizer.texts_to_sequences(loop_sentences)\n",
    "    \n",
    "    # concatenate the tokenized sequences\n",
    "    sequences = np.stack((sequence_tokens, structure_tokens, loop_tokens), axis=1)\n",
    "    sequences =  np.transpose(sequences, (0, 2, 1))\n",
    "    \n",
    "    # add the `bpps` features on top\n",
    "    bpps_sum = np.array(df['bpps_sum'].to_list())[:,:,np.newaxis]\n",
    "    bpps_max = np.array(df['bpps_max'].to_list())[:,:,np.newaxis]\n",
    "    bpps_nb = np.array(df['bpps_nb'].to_list())[:,:,np.newaxis]\n",
    "    \n",
    "    return np.concatenate([sequences, bpps_sum, bpps_max, bpps_nb], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In the same way we process the labels. We should just extract them and transform them into the correct shape. The resulting shape should be `(num_examples, 68, 5)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    labels = np.array(df[pred_cols].values.tolist())\n",
    "    labels = np.transpose(labels, (0, 2, 1))\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Before running our dataset from the prerpocess function, we need to add the extra info to the dataframe. Also, we need to separate the public and private test dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['bpps_sum'] = read_bpps_sum(train_df)\n",
    "train_df['bpps_max'] = read_bpps_max(train_df)\n",
    "train_df['bpps_nb'] = read_bpps_nb(train_df)\n",
    "\n",
    "test_df['bpps_sum'] = read_bpps_sum(test_df)\n",
    "test_df['bpps_max'] = read_bpps_max(test_df)\n",
    "test_df['bpps_nb'] = read_bpps_nb(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_test_df = test_df.query(\"seq_length == 107\")\n",
    "private_test_df = test_df.query(\"seq_length == 130\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are now ready to process the data set and make the features ready to be consumed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = process_features(train_df)\n",
    "y_train = process_labels(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define and train the model\n",
    "\n",
    "We are now ready to define our model. We have to do with sequences, thus, it makes sense to use RNNs. More specifically, we will use bidirectional Gated Recurrent Units (GRUs) and Long Short Term Memory cells (LSTM). The output layer shoud produce 5 numbers, so we can see this as a regression problem.\n",
    "\n",
    "First let us define two helper functions for GRUs and LSTMs and then, define the body of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "         tf.keras.layers.GRU(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The model has an embedding layer. The embedding layer inlay the tokenized categorical input into a high-dimensional latent space. For this example we treat the dimensionality of the embedding space as a hyper-parameter that we can use to fine-tune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, seq_length=TRAIN_SEQUENCE_LENGTH, pred_len=68,\n",
    "                embed_dim=EMBED_DIM,\n",
    "                hidden_dim=HIDDEN_DIM, dropout=DROPOUT, sp_dropout=SP_DROPOUT):\n",
    "    inputs = tf.keras.layers.Input(shape=(seq_length, 6))\n",
    "    \n",
    "    # split categorical and numerical features and concatenate them later.\n",
    "    cat_features = inputs[:, :, :3]\n",
    "    num_features = inputs[:, :, 3:]\n",
    "\n",
    "    # embed the categorical inputs\n",
    "    embed = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(cat_features)\n",
    "    \n",
    "    reshaped = tf.reshape(\n",
    "        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n",
    "    )\n",
    "    \n",
    "    # concatenate the numberical and embedded categorical features\n",
    "    concatenated = tf.keras.layers.concatenate([reshaped, num_features], axis=2)\n",
    "    \n",
    "    hidden = tf.keras.layers.SpatialDropout1D(sp_dropout)(concatenated)\n",
    "    \n",
    "    hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
    "    \n",
    "    truncated = hidden[:, :pred_len]\n",
    "    \n",
    "    out = tf.keras.layers.Dense(5, activation='linear')(truncated)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 107, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 107, 3)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 107, 3, 100)  1500        tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 107, 300)]   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_1 (Te [(None, 107, 3)]     0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 107, 303)     0           tf_op_layer_Reshape[0][0]        \n",
      "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d (SpatialDropo (None, 107, 303)     0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 107, 256)     442368      spatial_dropout1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 107, 256)     296448      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 107, 256)     296448      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 107, 256)     394240      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_2 (Te [(None, 68, 256)]    0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 68, 5)        1285        tf_op_layer_strided_slice_2[0][0]\n",
      "==================================================================================================\n",
      "Total params: 1,432,289\n",
      "Trainable params: 1,432,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Submissions are scored using MCRMSE (mean columnwise root mean squared error):\n",
    "\n",
    "<img src=\"images/mcrmse.png\" width=\"250\" style=\"margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "Thus, we should code this metric and use it as our objective (loss) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanColumnwiseRMSE(tf.keras.losses.Loss):\n",
    "    def __init__(self, name='MeanColumnwiseRMSE'):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We are now ready to compile and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(tf.optimizers.Adam(learning_rate=LR), loss=MeanColumnwiseRMSE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 - 5s - loss: 0.6003 - val_loss: 0.6292\n",
      "Epoch 2/100\n",
      "34/34 - 2s - loss: 0.5388 - val_loss: 0.6001\n",
      "Epoch 3/100\n",
      "34/34 - 2s - loss: 0.5214 - val_loss: 0.5927\n",
      "Epoch 4/100\n",
      "34/34 - 2s - loss: 0.5094 - val_loss: 0.5731\n",
      "Epoch 5/100\n",
      "34/34 - 2s - loss: 0.4923 - val_loss: 0.5624\n",
      "Epoch 6/100\n",
      "34/34 - 2s - loss: 0.4811 - val_loss: 0.5521\n",
      "Epoch 7/100\n",
      "34/34 - 2s - loss: 0.4736 - val_loss: 0.5452\n",
      "Epoch 8/100\n",
      "34/34 - 2s - loss: 0.4673 - val_loss: 0.5449\n",
      "Epoch 9/100\n",
      "34/34 - 2s - loss: 0.4622 - val_loss: 0.5349\n",
      "Epoch 10/100\n",
      "34/34 - 2s - loss: 0.4561 - val_loss: 0.5293\n",
      "Epoch 11/100\n",
      "34/34 - 2s - loss: 0.4519 - val_loss: 0.5253\n",
      "Epoch 12/100\n",
      "34/34 - 2s - loss: 0.4462 - val_loss: 0.5206\n",
      "Epoch 13/100\n",
      "34/34 - 2s - loss: 0.4418 - val_loss: 0.5188\n",
      "Epoch 14/100\n",
      "34/34 - 2s - loss: 0.4367 - val_loss: 0.5125\n",
      "Epoch 15/100\n",
      "34/34 - 2s - loss: 0.4317 - val_loss: 0.5063\n",
      "Epoch 16/100\n",
      "34/34 - 2s - loss: 0.4287 - val_loss: 0.5002\n",
      "Epoch 17/100\n",
      "34/34 - 2s - loss: 0.4237 - val_loss: 0.4974\n",
      "Epoch 18/100\n",
      "34/34 - 2s - loss: 0.4210 - val_loss: 0.4940\n",
      "Epoch 19/100\n",
      "34/34 - 2s - loss: 0.4173 - val_loss: 0.4921\n",
      "Epoch 20/100\n",
      "34/34 - 2s - loss: 0.4131 - val_loss: 0.4879\n",
      "Epoch 21/100\n",
      "34/34 - 2s - loss: 0.4112 - val_loss: 0.4867\n",
      "Epoch 22/100\n",
      "34/34 - 2s - loss: 0.4087 - val_loss: 0.4859\n",
      "Epoch 23/100\n",
      "34/34 - 2s - loss: 0.4065 - val_loss: 0.4831\n",
      "Epoch 24/100\n",
      "34/34 - 2s - loss: 0.4050 - val_loss: 0.4837\n",
      "Epoch 25/100\n",
      "34/34 - 2s - loss: 0.4026 - val_loss: 0.4776\n",
      "Epoch 26/100\n",
      "34/34 - 2s - loss: 0.4011 - val_loss: 0.4774\n",
      "Epoch 27/100\n",
      "34/34 - 2s - loss: 0.3988 - val_loss: 0.4747\n",
      "Epoch 28/100\n",
      "34/34 - 2s - loss: 0.3965 - val_loss: 0.4757\n",
      "Epoch 29/100\n",
      "34/34 - 2s - loss: 0.3952 - val_loss: 0.4742\n",
      "Epoch 30/100\n",
      "34/34 - 2s - loss: 0.3940 - val_loss: 0.4721\n",
      "Epoch 31/100\n",
      "34/34 - 2s - loss: 0.3924 - val_loss: 0.4732\n",
      "Epoch 32/100\n",
      "34/34 - 2s - loss: 0.3908 - val_loss: 0.4722\n",
      "Epoch 33/100\n",
      "34/34 - 2s - loss: 0.3902 - val_loss: 0.4738\n",
      "Epoch 34/100\n",
      "34/34 - 2s - loss: 0.3891 - val_loss: 0.4670\n",
      "Epoch 35/100\n",
      "34/34 - 2s - loss: 0.3878 - val_loss: 0.4683\n",
      "Epoch 36/100\n",
      "34/34 - 2s - loss: 0.3858 - val_loss: 0.4683\n",
      "Epoch 37/100\n",
      "34/34 - 2s - loss: 0.3846 - val_loss: 0.4658\n",
      "Epoch 38/100\n",
      "34/34 - 2s - loss: 0.3831 - val_loss: 0.4677\n",
      "Epoch 39/100\n",
      "34/34 - 2s - loss: 0.3818 - val_loss: 0.4642\n",
      "Epoch 40/100\n",
      "34/34 - 2s - loss: 0.3815 - val_loss: 0.4630\n",
      "Epoch 41/100\n",
      "34/34 - 2s - loss: 0.3804 - val_loss: 0.4638\n",
      "Epoch 42/100\n",
      "34/34 - 2s - loss: 0.3790 - val_loss: 0.4635\n",
      "Epoch 43/100\n",
      "34/34 - 2s - loss: 0.3779 - val_loss: 0.4628\n",
      "Epoch 44/100\n",
      "34/34 - 2s - loss: 0.3765 - val_loss: 0.4645\n",
      "Epoch 45/100\n",
      "34/34 - 2s - loss: 0.3768 - val_loss: 0.4626\n",
      "Epoch 46/100\n",
      "34/34 - 2s - loss: 0.3750 - val_loss: 0.4609\n",
      "Epoch 47/100\n",
      "34/34 - 2s - loss: 0.3744 - val_loss: 0.4631\n",
      "Epoch 48/100\n",
      "34/34 - 2s - loss: 0.3735 - val_loss: 0.4584\n",
      "Epoch 49/100\n",
      "34/34 - 2s - loss: 0.3728 - val_loss: 0.4620\n",
      "Epoch 50/100\n",
      "34/34 - 2s - loss: 0.3708 - val_loss: 0.4605\n",
      "Epoch 51/100\n",
      "34/34 - 2s - loss: 0.3698 - val_loss: 0.4586\n",
      "Epoch 52/100\n",
      "34/34 - 2s - loss: 0.3690 - val_loss: 0.4596\n",
      "Epoch 53/100\n",
      "34/34 - 2s - loss: 0.3686 - val_loss: 0.4587\n",
      "Epoch 54/100\n",
      "34/34 - 2s - loss: 0.3678 - val_loss: 0.4593\n",
      "Epoch 55/100\n",
      "34/34 - 2s - loss: 0.3665 - val_loss: 0.4629\n",
      "Epoch 56/100\n",
      "34/34 - 2s - loss: 0.3660 - val_loss: 0.4574\n",
      "Epoch 57/100\n",
      "34/34 - 2s - loss: 0.3653 - val_loss: 0.4596\n",
      "Epoch 58/100\n",
      "34/34 - 2s - loss: 0.3641 - val_loss: 0.4583\n",
      "Epoch 59/100\n",
      "34/34 - 2s - loss: 0.3635 - val_loss: 0.4594\n",
      "Epoch 60/100\n",
      "34/34 - 2s - loss: 0.3629 - val_loss: 0.4582\n",
      "Epoch 61/100\n",
      "34/34 - 2s - loss: 0.3618 - val_loss: 0.4574\n",
      "Epoch 62/100\n",
      "34/34 - 2s - loss: 0.3619 - val_loss: 0.4606\n",
      "Epoch 63/100\n",
      "34/34 - 2s - loss: 0.3604 - val_loss: 0.4594\n",
      "Epoch 64/100\n",
      "34/34 - 2s - loss: 0.3599 - val_loss: 0.4613\n",
      "Epoch 65/100\n",
      "34/34 - 2s - loss: 0.3599 - val_loss: 0.4587\n",
      "Epoch 66/100\n",
      "34/34 - 2s - loss: 0.3599 - val_loss: 0.4612\n",
      "Epoch 67/100\n",
      "34/34 - 2s - loss: 0.3583 - val_loss: 0.4563\n",
      "Epoch 68/100\n",
      "34/34 - 2s - loss: 0.3576 - val_loss: 0.4577\n",
      "Epoch 69/100\n",
      "34/34 - 2s - loss: 0.3570 - val_loss: 0.4561\n",
      "Epoch 70/100\n",
      "34/34 - 2s - loss: 0.3568 - val_loss: 0.4549\n",
      "Epoch 71/100\n",
      "34/34 - 2s - loss: 0.3557 - val_loss: 0.4570\n",
      "Epoch 72/100\n",
      "34/34 - 2s - loss: 0.3554 - val_loss: 0.4587\n",
      "Epoch 73/100\n",
      "34/34 - 2s - loss: 0.3544 - val_loss: 0.4575\n",
      "Epoch 74/100\n",
      "34/34 - 2s - loss: 0.3540 - val_loss: 0.4559\n",
      "Epoch 75/100\n",
      "34/34 - 2s - loss: 0.3539 - val_loss: 0.4558\n",
      "Epoch 76/100\n",
      "34/34 - 2s - loss: 0.3526 - val_loss: 0.4544\n",
      "Epoch 77/100\n",
      "34/34 - 2s - loss: 0.3527 - val_loss: 0.4560\n",
      "Epoch 78/100\n",
      "34/34 - 2s - loss: 0.3524 - val_loss: 0.4547\n",
      "Epoch 79/100\n",
      "34/34 - 2s - loss: 0.3519 - val_loss: 0.4567\n",
      "Epoch 80/100\n",
      "34/34 - 2s - loss: 0.3518 - val_loss: 0.4570\n",
      "Epoch 81/100\n",
      "34/34 - 2s - loss: 0.3501 - val_loss: 0.4562\n",
      "Epoch 82/100\n",
      "34/34 - 2s - loss: 0.3500 - val_loss: 0.4562\n",
      "Epoch 83/100\n",
      "34/34 - 2s - loss: 0.3493 - val_loss: 0.4560\n",
      "Epoch 84/100\n",
      "34/34 - 2s - loss: 0.3485 - val_loss: 0.4582\n",
      "Epoch 85/100\n",
      "34/34 - 2s - loss: 0.3488 - val_loss: 0.4599\n",
      "Epoch 86/100\n",
      "34/34 - 2s - loss: 0.3485 - val_loss: 0.4552\n",
      "Epoch 87/100\n",
      "34/34 - 2s - loss: 0.3473 - val_loss: 0.4550\n",
      "Epoch 88/100\n",
      "34/34 - 2s - loss: 0.3474 - val_loss: 0.4553\n",
      "Epoch 89/100\n",
      "34/34 - 2s - loss: 0.3468 - val_loss: 0.4569\n",
      "Epoch 90/100\n",
      "34/34 - 2s - loss: 0.3469 - val_loss: 0.4553\n",
      "Epoch 91/100\n",
      "34/34 - 2s - loss: 0.3459 - val_loss: 0.4567\n",
      "Epoch 92/100\n",
      "34/34 - 2s - loss: 0.3451 - val_loss: 0.4541\n",
      "Epoch 93/100\n",
      "34/34 - 2s - loss: 0.3445 - val_loss: 0.4535\n",
      "Epoch 94/100\n",
      "34/34 - 2s - loss: 0.3444 - val_loss: 0.4579\n",
      "Epoch 95/100\n",
      "34/34 - 2s - loss: 0.3444 - val_loss: 0.4543\n",
      "Epoch 96/100\n",
      "34/34 - 2s - loss: 0.3436 - val_loss: 0.4587\n",
      "Epoch 97/100\n",
      "34/34 - 2s - loss: 0.3436 - val_loss: 0.4574\n",
      "Epoch 98/100\n",
      "34/34 - 2s - loss: 0.3431 - val_loss: 0.4565\n",
      "Epoch 99/100\n",
      "34/34 - 2s - loss: 0.3425 - val_loss: 0.4586\n",
      "Epoch 100/100\n",
      "34/34 - 2s - loss: 0.3428 - val_loss: 0.4544\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_split=.1,\n",
    "          batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=2,\n",
    "          callbacks=[\n",
    "              tf.keras.callbacks.ModelCheckpoint(\"model_v0.3.1.h5\", save_best_only=True)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/jovyan/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model_v0.3.1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model_v0.3.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Finally, we are ready to evaluate the model using the two test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "public_test_data = process_features(public_test_df)\n",
    "private_test_data = process_features(private_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_public = build_model(vocab_size, seq_length=107, pred_len=107)\n",
    "model_private = build_model(vocab_size, seq_length=130, pred_len=130)\n",
    "\n",
    "model_public.load_weights(\"model_v0.3.1.h5\")\n",
    "model_private.load_weights(\"model_v0.3.1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "block:model_public"
    ]
   },
   "outputs": [],
   "source": [
    "public_preds = model_public.predict(public_test_data)\n",
    "private_preds = model_private.predict(private_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Submission\n",
    "\n",
    "Last but note least, we create our submission to the Kaggle competition. The submission is just a `csv` file with the specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reactivity</th>\n",
       "      <th>deg_Mg_pH10</th>\n",
       "      <th>deg_Mg_50C</th>\n",
       "      <th>deg_pH10</th>\n",
       "      <th>deg_50C</th>\n",
       "      <th>id_seqpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.596071</td>\n",
       "      <td>0.631319</td>\n",
       "      <td>0.551407</td>\n",
       "      <td>2.139716</td>\n",
       "      <td>0.776833</td>\n",
       "      <td>id_00073f8be_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.168637</td>\n",
       "      <td>3.062203</td>\n",
       "      <td>3.149908</td>\n",
       "      <td>4.406666</td>\n",
       "      <td>2.887317</td>\n",
       "      <td>id_00073f8be_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.469406</td>\n",
       "      <td>0.482637</td>\n",
       "      <td>0.550827</td>\n",
       "      <td>0.638930</td>\n",
       "      <td>0.678040</td>\n",
       "      <td>id_00073f8be_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.182739</td>\n",
       "      <td>0.983551</td>\n",
       "      <td>1.492946</td>\n",
       "      <td>1.109593</td>\n",
       "      <td>1.662937</td>\n",
       "      <td>id_00073f8be_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.871908</td>\n",
       "      <td>0.596964</td>\n",
       "      <td>0.859137</td>\n",
       "      <td>0.555157</td>\n",
       "      <td>0.868398</td>\n",
       "      <td>id_00073f8be_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reactivity  deg_Mg_pH10  deg_Mg_50C  deg_pH10   deg_50C       id_seqpos\n",
       "0    0.596071     0.631319    0.551407  2.139716  0.776833  id_00073f8be_0\n",
       "1    2.168637     3.062203    3.149908  4.406666  2.887317  id_00073f8be_1\n",
       "2    1.469406     0.482637    0.550827  0.638930  0.678040  id_00073f8be_2\n",
       "3    1.182739     0.983551    1.492946  1.109593  1.662937  id_00073f8be_3\n",
       "4    0.871908     0.596964    0.859137  0.555157  0.868398  id_00073f8be_4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ls = []\n",
    "\n",
    "for df, preds in [(public_test_df, public_preds), (private_test_df, private_preds)]:\n",
    "    for i, uid in enumerate(df.id):\n",
    "        single_pred = preds[i]\n",
    "\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "        preds_ls.append(single_df)\n",
    "\n",
    "preds_df = pd.concat(preds_ls)\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = sample_submission_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "docker_image": "gcr.io/arrikto-playground/jupyter-kale:beb3b7f-03892c7",
   "experiment": {
    "id": "",
    "name": ""
   },
   "experiment_name": "",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "",
   "snapshot_volumes": true,
   "steps_defaults": [
    "label:access-ml-pipeline:true",
    "label:access-rok:true"
   ],
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "workspace-examples-server-l7q82ak70",
     "size": 10,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
